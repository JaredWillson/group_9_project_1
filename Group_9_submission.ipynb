{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2688d5b8-935e-4b4a-a243-ffbe7768b120",
   "metadata": {},
   "source": [
    "# US Census Data API/Data Collection\n",
    "## ACS Survey 5\n",
    "\n",
    "The ACS Survey 5 contains data from 2019 to 2022 and includes social, economic, demographic, and housing data all the way down to the zip code level. Our group has decided to use zip code level data for our analysis. We can then split zip codes into urban/rural and into various household income buckets. We can also summarize across the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc30d64-a01e-45e8-80ac-388ebdf32446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# Requests will let us send HTTP requests and return a result. \n",
    "# Numpy will let us perform various mathematical functions that may be requried\n",
    "# Pandas lets us work with dataframes\n",
    "# Census lets us submit simplified census API requests\n",
    "# The Pypi library 'states' provides FIPS lookup functionality as well as other\n",
    "# geography codes\n",
    "# The config.py file contains the census API key\n",
    "# And matplotlib will allow the creation of visualizations.\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from census import Census\n",
    "from us import states\n",
    "from config import census_api_key\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958284e-72ea-4242-9825-f1f63b82526a",
   "metadata": {},
   "source": [
    "## Data Requirements\n",
    "\n",
    "So, what data will we need to collect? \n",
    "\n",
    "For all zip codes in california: \n",
    "For the five years we are interested in:\n",
    "-        What is the population by zip code?\n",
    "-        What is the geographic area by zip code\n",
    "-        What is the household income by zip code\n",
    "\n",
    "It may be worth exploring to see if there are other data that would be helpful for answering some intriguing questions, but this should be enough to cover the questions already identified in our project. We can marry these data with the information on car registration by fuel from the california government website as well as California energy department info on energy production.\n",
    "\n",
    "At present, I don't have geographic area by zip code. Census does not publish this. They do publish population density, but not by zip code. May need to summarize by county since zip codes are by residence, not technically a geographic area. See the \"Alternate Data Sets\" section for these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9f9a6a-ae9d-46a0-9be4-08bbf597fb83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    417\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# for the host.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m send_sni:\n\u001b[1;32m--> 449\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m server_hostname:\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\ssl.py:1375\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1374\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1375\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 798\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\util\\retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\packages\\six.py:769\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    417\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# for the host.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m send_sni:\n\u001b[1;32m--> 449\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m server_hostname:\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\ssl.py:1375\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1374\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1375\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2018\u001b[39m, \u001b[38;5;241m2023\u001b[39m):\n\u001b[0;32m      9\u001b[0m     c \u001b[38;5;241m=\u001b[39m Census(\n\u001b[0;32m     10\u001b[0m         census_api_key,\n\u001b[0;32m     11\u001b[0m         year \u001b[38;5;241m=\u001b[39m year\n\u001b[0;32m     12\u001b[0m     )\n\u001b[1;32m---> 13\u001b[0m     census_data \u001b[38;5;241m=\u001b[39m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macs5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNAME\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mB19013_001E\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mB01003_001E\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzip code tabulation area:*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     census_pd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(census_data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\census\\core.py:317\u001b[0m, in \u001b[0;36mACSClient.get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_endpoints(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_year))\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(ACSClient, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\census\\core.py:159\u001b[0m, in \u001b[0;36mClient.get\u001b[1;34m(self, fields, geo, year, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m sort_by_geoid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fields) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m49\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m year \u001b[38;5;129;01mor\u001b[39;00m year \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2009\u001b[39m)\n\u001b[0;32m    157\u001b[0m all_results \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(forty_nine_fields, geo, year, sort_by_geoid\u001b[38;5;241m=\u001b[39msort_by_geoid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m forty_nine_fields \u001b[38;5;129;01min\u001b[39;00m chunks(fields, \u001b[38;5;241m49\u001b[39m))\n\u001b[1;32m--> 159\u001b[0m merged_results \u001b[38;5;241m=\u001b[39m [merge(result) \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_results\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_results\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\census\\core.py:157\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03mThe API only accepts up to 50 fields on each query.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03mChunk requests, and use the unique GEO_ID to match up the chunks\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03min case the responses are in different orders.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03mGEO_ID is not reliably present in pre-2010 requests.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m sort_by_geoid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fields) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m49\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m year \u001b[38;5;129;01mor\u001b[39;00m year \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2009\u001b[39m)\n\u001b[1;32m--> 157\u001b[0m all_results \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(forty_nine_fields, geo, year, sort_by_geoid\u001b[38;5;241m=\u001b[39msort_by_geoid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m forty_nine_fields \u001b[38;5;129;01min\u001b[39;00m chunks(fields, \u001b[38;5;241m49\u001b[39m))\n\u001b[0;32m    159\u001b[0m merged_results \u001b[38;5;241m=\u001b[39m [merge(result) \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_results)]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_results\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\census\\core.py:60\u001b[0m, in \u001b[0;36mretry_on_transient_error.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m         result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m CensusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was an error while running your query.  We\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve logged the error and we\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mll correct it ASAP.  Sorry for the inconvenience.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\census\\core.py:186\u001b[0m, in \u001b[0;36mClient.query\u001b[1;34m(self, fields, geo, year, sort_by_geoid, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m geo:\n\u001b[0;32m    184\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m geo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 186\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\requests\\sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\requests\\adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Census library\n",
    "# Run Census Search to retrieve data on all zip codes (2018 to 2022 ACS5 Census--latest five years)\n",
    "# We'll need a for loop to go through the years from 2018 to 2022\n",
    "# For loops stop just before the last member of the range since it is a zero index system\n",
    "\n",
    "multi_census_pd = pd.DataFrame()\n",
    "\n",
    "for year in range(2018, 2023):\n",
    "    c = Census(\n",
    "        census_api_key,\n",
    "        year = year\n",
    "    )\n",
    "    census_data = c.acs5.get(\n",
    "        (\n",
    "            \"NAME\",\n",
    "            \"B19013_001E\",\n",
    "            \"B01003_001E\",\n",
    "        ),\n",
    "        {'for': 'zip code tabulation area:*'}\n",
    "    )\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    census_pd = pd.DataFrame(census_data)\n",
    "\n",
    "    # Column renaming\n",
    "    census_pd = census_pd.rename(\n",
    "        columns = {\n",
    "            \"NAME\": \"Name\",\n",
    "            \"B19013_001E\": \"Household Income\",\n",
    "            \"B01003_001E\": \"Population\",\n",
    "            \"zip code tabulation area\": \"Zipcode\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Configure the final DataFrame (basically, just drop the \"Name\" column)\n",
    "    census_pd = census_pd[\n",
    "        [\n",
    "            \"Zipcode\",\n",
    "            \"Population\",\n",
    "            \"Household Income\",\n",
    "        ]\n",
    "    ]\n",
    "    census_pd['Year'] = year\n",
    "\n",
    "    multi_census_pd = pd.concat([census_pd, multi_census_pd], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953ffda-cf65-4402-a916-175ebcfe3748",
   "metadata": {},
   "source": [
    "## Filters/Slices\n",
    "\n",
    "I will need to filter this dataset down to just show California zip codes and add in their city, longitude, latitude in case\n",
    "we want to plot something on a map, or in case we want to group by city or something like that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b43709-08ce-424d-ac2a-f44c8f84b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to filter by state, we can use a csv file that is available from US census containing all \n",
    "# states, cities, zips, and the state_fips abbreviation.\n",
    "\n",
    "zip_state_pd = pd.read_csv(\"Resources/geo-data.csv\")\n",
    "\n",
    "# Now, we just need to merge our two dataframes to get just the California values\n",
    "multi_census_pd = multi_census_pd.merge(zip_state_pd, how='inner', left_on = 'Zipcode', right_on = 'zipcode', copy='false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b4531-8912-4a75-ab6a-94649bda7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, now let's do some cleanup and drop states we don't need...\n",
    "multi_census_pd.drop(columns='zipcode', inplace=True)\n",
    "multi_census_pd = multi_census_pd[multi_census_pd['state_abbr'] == 'CA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346f4ad-0186-4de1-abc2-d39626ed1219",
   "metadata": {},
   "source": [
    "## Data Cleansing and Output\n",
    "\n",
    "I will need to cleanse the data a bit so that I get rid of NaN's and negative income values in the raw census data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86181b-255f-43d3-8c88-0b015a8d85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to drop the following rows:\n",
    "#     1) Any rows where the population is zero (to reduce risk of dividing by zero)\n",
    "#     2) Any rows where Household Income is negative\n",
    "#     3) Any rows missing cities (in case we end up agregating by city)\n",
    "#     4) Any rows missing counties (in case we end up agregating by county)\n",
    "#     5) Any rows where the city is just a ZCTA (zip code), not an actual city name\n",
    "#     6) Any rows where the count by zip code is less than 5, so we don't have mismatched data by year\n",
    "#        --basically situations where maybe there are data for one year for a given zip, but not for another year\n",
    "\n",
    "multi_census_pd = multi_census_pd[multi_census_pd['Population']!= 0]\n",
    "multi_census_pd = multi_census_pd[multi_census_pd['Household Income']> 0]\n",
    "multi_census_pd = multi_census_pd[multi_census_pd['city'].notna()]\n",
    "multi_census_pd = multi_census_pd[multi_census_pd['county'].notna()]\n",
    "multi_census_pd = multi_census_pd[multi_census_pd['city'].str.startswith('Zcta') == False]\n",
    "\n",
    "# To do number 6 above, we need to first make a list of zip codes\n",
    "# Where the row count is less than five (since we ran this for five years)\n",
    "keepzip = multi_census_pd.groupby('Zipcode').count()\n",
    "keepzip = keepzip.loc[keepzip['city'] == 5]\n",
    "# Now we can delete any rows from multi_census_pd\n",
    "# Where the Zipcode is not in the 'keepzip' file\n",
    "multi_census_pd = multi_census_pd[multi_census_pd['Zipcode'].isin(keepzip.index)]\n",
    "\n",
    "multi_census_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064eb454-e319-4358-8597-cd43cf1420b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can write out our data file for incorporation into the master Pandas notebook\n",
    "multi_census_pd.to_csv(\"Resources/census_data.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1172d1-6ca6-4522-99dd-7ac3cfb1ff89",
   "metadata": {},
   "source": [
    "## Alternate Data Set (by County rather than Zip since not all data available by Zip)\n",
    "Not all of the diferent datasets are available by zip code, so I need to prepare a couple different files:\n",
    "- Census data by county\n",
    "- A cross reference from zip code to county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89c43e-5915-47aa-92d2-e5724ff207c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Census library\n",
    "# Run Census Search to retrieve data on all counties (2018 to 2022 ACS5 Census--latest five years)\n",
    "# We'll need a for loop to go through the years from 2018 to 2022\n",
    "# For: loops stop just before the last member of the range since it is a zero index system\n",
    "# We'll start by creating an empty dataframe that we will hold all of our data for each year...\n",
    "\n",
    "multi_census_county = pd.DataFrame()\n",
    "\n",
    "for year in range(2018, 2023):\n",
    "    c = Census(\n",
    "        census_api_key,\n",
    "        year = year\n",
    "    )\n",
    "    census_data = c.acs5.get(\n",
    "        (\n",
    "            \"NAME\",\n",
    "            \"B19013_001E\",\n",
    "            \"B01003_001E\"\n",
    "        ),\n",
    "        {'for': 'county:*', 'in': 'state:06'}\n",
    "    )\n",
    "\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    census_pd = pd.DataFrame(census_data)\n",
    "\n",
    "    # Column renaming\n",
    "    census_pd = census_pd.rename(\n",
    "        columns = {\n",
    "            \"NAME\": \"Name\",\n",
    "            \"B19013_001E\": \"Household Income\",\n",
    "            \"B01003_001E\": \"Population\",\n",
    "            \"county\": \"County FIPS\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # Configure the final DataFrame (basically, just drop the \"Name\" column)\n",
    "    census_pd = census_pd[\n",
    "        [\n",
    "            \"County FIPS\",\n",
    "            \"Population\",\n",
    "            \"Household Income\",\n",
    "        ]\n",
    "    ]\n",
    "    census_pd['Year'] = year\n",
    "\n",
    "    multi_census_county = pd.concat([census_pd, multi_census_county], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd6a29-86b9-47ba-9d9d-58b40c195219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But our county FIPS does not tell us the name of the county.\n",
    "# We can pull in a CSV with a FIPS lookup value for California taken from US Census SF1\n",
    "\n",
    "# We need to make sure the FIPS column isn't interpreted as a number, so we specify the dtype explicitly\n",
    "county_name_pd = pd.read_csv('Resources/census_county_name_fips.csv', dtype={\n",
    "    'Name': 'string',\n",
    "    'FIPS': 'string'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9170773-ab04-4af8-890f-fc1a4bd5ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, now we will join our county name cross reference to our dataset...\n",
    "multi_census_county = multi_census_county.merge(county_name_pd,\n",
    "                                                how='inner',\n",
    "                                                left_on = 'County FIPS',\n",
    "                                                right_on = 'FIPS',\n",
    "                                                copy = 'false'\n",
    "                                               )\n",
    "# Then, we will do a little cleanup--renaming columns, dropping the FIPS columns, and reordering...\n",
    "multi_census_county = multi_census_county.rename(columns={\"Name\": \"County\"})\n",
    "multi_census_county.drop('County FIPS', axis=1, inplace=True)\n",
    "multi_census_county.drop('FIPS', axis=1, inplace=True)\n",
    "multi_census_county = multi_census_county[['County', 'Year', 'Population', 'Household Income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8c247-8c67-43e1-bc1d-0f4bc4afdac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While this dataset appears to be much cleaner than the ZIP dataset,\n",
    "# just as a precaution we will run whatever cleanup code still applies\n",
    "# from our analysis of the ZIP dataset.\n",
    "\n",
    "multi_census_county = multi_census_county[multi_census_county['Population']!= 0]\n",
    "multi_census_county = multi_census_county[multi_census_county['Household Income']> 0]\n",
    "multi_census_county = multi_census_county[multi_census_county['County'].notna()]\n",
    "\n",
    "multi_census_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29650c3-7e4c-4903-a609-80293837a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can write our data set to a CSV file for any of the collaborators to use...\n",
    "multi_census_county.to_csv(\"Resources/census_data_by_county.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e803fe30-c493-409a-8239-728ec98fe3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We still need to make a file containing the zip codes and the counties\n",
    "# so that we can summarize by county in situations where there is no zipcode level information\n",
    "\n",
    "zipcode_county_pd = multi_census_pd.loc[multi_census_pd['Year'] == 2022]\n",
    "zipcode_county_pd = zipcode_county_pd[\n",
    "        [\n",
    "            \"Zipcode\",\n",
    "            \"county\"\n",
    "        ]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2dd2f-9cde-4a01-bf2b-ec5f6af48ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we will write out our zip/county cross reference file for anyone who needs it...\n",
    "zipcode_county_pd.to_csv(\"Resources/zip_to_county.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a47bd5-8473-4daa-bf25-52ca27b9223a",
   "metadata": {},
   "source": [
    "## Extrapolation\n",
    "Since not all our datasets are available for the same years, as a team we decided\n",
    "that we would extrapolate out the census data to the year 2023 in order to come up with the most\n",
    "recent five year period for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bdc4d2-4180-4949-abee-7517e008b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode: for the multi_census_county dataframe, we will want to group by the county, grab the 2018 value for each of population and\n",
    "# household income, grab the 2022 value, find the difference, divide by four (the number of years of change). This will\n",
    "# be the average yearly change. \n",
    "#\n",
    "# Then we will create a 2023 value of each of population and household income that is the sum of the 2022 value and this delta.\n",
    "\n",
    "# Using Alameda County as an example, grab the 2022 value of \"Population\" (1663823), the 2018 value (1643700), find the difference (20123),\n",
    "# divide by 4, convert to an integer since you can't have fractional people (5031) , And add that value to the 2022 value so we get \n",
    "# an extrampolated 2023 population value for Alameda County of 1668854- a slight increase over 2022.\n",
    "#\n",
    "# The same can be done for Household income. It has gone (in Alameda) from 92574 in 2018 to 122488 in 2022. That's an increae of 29914 in 4 years.\n",
    "# So that's an average increase of 7479 per year (integer value again). So we add 7479 to our 2022 number and get 129967 as our 2023 household income.\n",
    "\n",
    "\n",
    "delta_start = multi_census_county.loc[multi_census_county['Year'] == 2018]\n",
    "delta_start = delta_start.rename(columns={\"Population\": \"Start Pop\",\n",
    "                                          \"Household Income\": \"Start Income\"\n",
    "                                         })\n",
    "delta_end = multi_census_county.loc[multi_census_county['Year'] == 2022]\n",
    "delta_end = delta_end.rename(columns={\"Population\": \"End Pop\",\n",
    "                                          \"Household Income\": \"End Income\"\n",
    "                                       })\n",
    "delta_start.drop('Year', axis=1, inplace=True)\n",
    "delta_end.drop('Year', axis=1, inplace=True)\n",
    "delta = delta_start.merge(delta_end, how='inner', on='County')\n",
    "delta[\"Pop Delta\"] = round((delta[\"End Pop\"] - delta[\"Start Pop\"]) / 4, 0)\n",
    "delta[\"Inc Delta\"] = round((delta[\"End Income\"] - delta[\"Start Income\"]) / 4, 0)\n",
    "delta[\"Population\"] = delta[\"End Pop\"] + delta[\"Pop Delta\"]\n",
    "delta[\"Household Income\"] = delta[\"End Income\"] + delta[\"Inc Delta\"]\n",
    "delta.drop(['Start Pop', 'Start Income', 'End Pop', 'End Income', 'Pop Delta', 'Inc Delta'], axis=1, inplace=True)\n",
    "delta[\"Year\"] = 2023\n",
    "delta = delta[['County', 'Year', 'Population', 'Household Income']]\n",
    "census_county_extrapolate = pd.concat([delta, multi_census_county], axis=0)\n",
    "census_county_extrapolate = census_county_extrapolate.sort_values(by=['County','Year'],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119476b-68e5-408f-80d0-e3f84bb6019b",
   "metadata": {},
   "source": [
    "## Include Geograpic Area by County\n",
    "\n",
    "In order to determine whether there are differences in adoption by county, we will need to know the area of each county, then we can calculate population density by dividing population by area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932139a4-4f11-4df9-b3d4-7f5cc9173454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we import a data file containing the area in square miles for each county\n",
    "\n",
    "county_area_pd = pd.read_csv(\"Resources/census_county_area.csv\")\n",
    "\n",
    "# Now, we can merge this with our extrapolated, complete dataset...\n",
    "\n",
    "census_county_extrapolate = census_county_extrapolate.merge(county_area_pd, how='inner', on='County')\n",
    "census_county_extrapolate[\"Density\"] = census_county_extrapolate[\"Population\"] / census_county_extrapolate[\"Area (sq mi)\"]\n",
    "\n",
    "# Time to write out our results...\n",
    "\n",
    "census_county_extrapolate.to_csv(\"Resources/census_data_by_county_with_2023.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ef751-ae64-469b-b42d-9254bc6e7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_county_extrapolate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8cf18-6542-49ea-9b8e-d66d18ea8c5f",
   "metadata": {},
   "source": [
    "## Merge Datasets for Visualizations\n",
    "\n",
    "Now, we need to bring in data created by other collaborators.  First, we will bring in the DMV data generated by Gina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c1b72-1a51-47b7-a511-d66ec54170d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to import the DMV data into a Pandas dataframe...\n",
    "\n",
    "battery_electric_df = pd.read_csv('battery_electric_totals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6088b-b2d3-4916-a709-484777b839fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_electric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eddf5e-0581-4bcf-9476-db15682e2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can merge those data with the existing census dataframe so that we have\n",
    "# the combination of County, Year, Population, Income, Pop Density, and number of\n",
    "# vehicles registered that year\n",
    "\n",
    "merged_census_DMV = census_county_extrapolate.merge(battery_electric_df,\n",
    "                                                    how='inner',\n",
    "                                                    left_on = ['County', 'Year'],\n",
    "                                                    right_on = ['county', 'Year'],\n",
    "                                                    copy='false')\n",
    "\n",
    "# We can drop a couple column that aren't needed. First, we have two county columns, so dropping one\n",
    "# Second, we don't need to specify the fuel since the only records in the dataframe are EV's\n",
    "merged_census_DMV.drop('county', axis=1, inplace=True)\n",
    "merged_census_DMV.drop('Fuel', axis=1, inplace=True)\n",
    "\n",
    "merged_census_DMV.loc[merged_census_DMV['County'] == 'Los Angeles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a990d9b-3a14-4bb3-988a-b57023409d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For purposes of determining Urban vs Rural counties, the US Census bureau uses a combination of factors\n",
    "# involving both the size of the population center (number of total people in the city) as well as \n",
    "# the population density. However, this does not perfectly match with either zip code or county. From examining\n",
    "# the California data, the best approximation is that all (or nearly all) counties with a population density \n",
    "# greater than 1,000 people per square mile is a good cutoff point.  So, we will classify our counties as either urban\n",
    "# or rural (those are the only two groupings for the US Census) based upon this threshold.\n",
    "#\n",
    "# In order to minimize the risk of unintended results in the visualizations, I will use the 2022 numbers\n",
    "# of population density to assign a value of \"urban\" or \"rural\" to each county, regardless of whether\n",
    "# other years are slightly above or below the threshold. \n",
    "# \n",
    "# To do this, I will calculate the value for all rows, then overwrite years other than 2022 with the 2022 \n",
    "# classification\n",
    "\n",
    "# First, set a starting value of Urban...\n",
    "# then update it to Rural if the density is below 1,000 people per square mile\n",
    "merged_census_DMV['Classification'] = 'Urban'\n",
    "merged_census_DMV['Classification'] = merged_census_DMV['Classification'].where(merged_census_DMV['Density'] > 1000, 'Rural')\n",
    "\n",
    "# Now, we need to make sure any given county isn't fluctuating from one year to the next...\n",
    "# So, we will make a dataframe with just the 2022 values\n",
    "merged_census_DMV_2022 = merged_census_DMV.loc[merged_census_DMV['Year'] == 2022]\n",
    "# Then, we will set to the classification for all years based on the 2022 values\n",
    "# By merging the two dataframes together\n",
    "# Then dropping the 'Classification' in favor of the '2022 Classification'\n",
    "merged_census_DMV = merged_census_DMV.merge(merged_census_DMV_2022,\n",
    "                                            how='inner',\n",
    "                                            on='County',\n",
    "                                            copy = 'false'\n",
    "                                           )\n",
    "# Now we just need to clean up the result...\n",
    "merged_census_DMV.drop(['Classification_x',\n",
    "                      'Year_y',\n",
    "                      'Population_y',\n",
    "                      'Household Income_y',\n",
    "                      'Area (sq mi)_y',\n",
    "                      'Density_y',\n",
    "                      'Vehicles_y',\n",
    "                      'Classification_x'], \n",
    "                      axis=1, \n",
    "                      inplace=True)\n",
    "merged_census_DMV.columns = ['County',\n",
    "                             'Year',\n",
    "                             'Population',\n",
    "                             'Household Income',\n",
    "                             'Area (sq mi)',\n",
    "                             'Density',\n",
    "                             'Vehicles',\n",
    "                             'Classification'\n",
    "                            ]\n",
    "merged_census_DMV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872ca27-1d37-4d11-8cc1-22b80c8aa068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write out that dataframe in case anyone else needs it for their visualizations...\n",
    "merged_census_DMV.to_csv(\"Resources/census_and_dmv_data.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5fd182-4e22-4008-a9dd-d333c7ffe6c2",
   "metadata": {},
   "source": [
    "## Aggregations\n",
    "We will need to aggregate our data set different ways in order to support different visualizations. The first question from our charter is, \"What is the adoption rate for EV's in urban vs rural areas?\" To answer that, we need to aggregate our data so that instead of each county, we are looking at two data sets, by year, one for rural and one for urban."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea6dd6-5df2-4514-af89-7b41bf30cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first question from our charter is, \"What is the adoption rate for\n",
    "# EV's in urban vs. rural areas?\"  To answer that, we need to aggregate our databy Classification\n",
    "# and we will want a summary data set for the entire state. That way we can plot two separate\n",
    "# data sets in the same visualization\n",
    "\n",
    "rural_ev_adoption = merged_census_DMV.loc[merged_census_DMV['Classification'] == 'Rural']\n",
    "urban_ev_adoption = merged_census_DMV.loc[merged_census_DMV['Classification'] == 'Urban']\n",
    "summary_rural_adoption = rural_ev_adoption.groupby('Year').agg({'Vehicles': 'sum'})\n",
    "summary_urban_adoption = urban_ev_adoption.groupby('Year').agg({'Vehicles': 'sum'})\n",
    "aggregated_rural = rural_ev_adoption.groupby('Year').agg({'Vehicles': 'sum', 'Population': 'sum'})\n",
    "aggregated_urban = urban_ev_adoption.groupby('Year').agg({'Vehicles': 'sum', 'Population': 'sum'})\n",
    "aggregated_rural['Vehicles per 100K'] = aggregated_rural['Vehicles'] / (aggregated_rural['Population'] / 100000)\n",
    "aggregated_urban['Vehicles per 100K'] = aggregated_urban['Vehicles'] / (aggregated_urban['Population'] / 100000)\n",
    "\n",
    "# To give a little more granularity, we'll want to run this by county as well. The chart\n",
    "# is likely to get a bit \"busy\", though, if we include all 58 counties (or the 56 we have valid data\n",
    "# for), so let's see how many urban and rural counties we need to include (same number of each)\n",
    "# in order to capture 75% of the California population... We can use 2022 data to see\n",
    "\n",
    "total_population = merged_census_DMV.groupby('Year').sum()\n",
    "total_population = total_population.loc[total_population.index == 2022]['Population']\n",
    "total_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756ddf8-5c1f-4e46-b2b0-aa653a7ba9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the total population in California, per the 2022 census, is 39,000,000 people\n",
    "# Let's see how many counties we need, both urban and rural, to capture 29,000,000 people. \n",
    "# Using this subset will make our visualization much less cluttered and will still be\n",
    "# a good representation of the state as a whole.\n",
    "# Trial and error will probably be easiest. Let's see what percentage of the population we get if we\n",
    "# choose the six largest urban counties and six largest rural counties...\n",
    "\n",
    "rural_ev_adoption_2022 = rural_ev_adoption.loc[rural_ev_adoption['Year'] == 2022]\n",
    "rural_ev_top8 = rural_ev_adoption_2022.sort_values(by='Population',ignore_index=True, ascending=False)\n",
    "rural_ev_top8 = rural_ev_top8.iloc[:8]\n",
    "rural_ev_top8['Population'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2bb9c-afe1-45a1-856e-2eabda7d5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, we have 12 million people by choosing the population of the 6 largest rural counties. Let's do\n",
    "# the same for the ten largest urban counties...\n",
    "\n",
    "urban_ev_adoption_2022 = urban_ev_adoption.loc[urban_ev_adoption['Year'] == 2022]\n",
    "urban_ev_top8 = urban_ev_adoption_2022.sort_values(by='Population',ignore_index=True, ascending=False)\n",
    "urban_ev_top8 = urban_ev_top8.iloc[:8]\n",
    "urban_ev_top8['Population'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a56ff7-29cd-4b31-aec1-47abd7db097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, that gets us about 33 million people or 85% of the population. That seems like a \n",
    "# reasonable compromise between creating a visualization that is overly busy, and a visualization\n",
    "# that doesn't have a good representative set of counties.\n",
    "# \n",
    "# We'll need the dataset across all three years, though, so let's grab all the rural\n",
    "# and all the urban data, but just using the counties in our \"top7\" list...\n",
    "\n",
    "rural_ev_adoption_largest = rural_ev_adoption[rural_ev_adoption['County'].isin(rural_ev_top8['County'].tolist())].reindex()\n",
    "urban_ev_adoption_largest = urban_ev_adoption[urban_ev_adoption['County'].isin(urban_ev_top8['County'].tolist())].reindex()\n",
    "\n",
    "# We need to normalize these data by looking at vehicles per 100,000 population... Same as we did for the full\n",
    "# state data earlier.\n",
    "\n",
    "rural_ev_adoption_largest['Vehicles per 100K'] = rural_ev_adoption_largest['Vehicles'] / (rural_ev_adoption_largest['Population'] / 100000)\n",
    "urban_ev_adoption_largest['Vehicles per 100K'] = urban_ev_adoption_largest['Vehicles'] / (urban_ev_adoption_largest['Population'] / 100000)\n",
    "rural_ev_adoption_largest.drop(['Population',\n",
    "                                'Household Income',\n",
    "                                'Area (sq mi)',\n",
    "                                'Density',\n",
    "                                'Classification',\n",
    "                                'Vehicles'],\n",
    "                               axis=1,\n",
    "                               inplace=True)\n",
    "urban_ev_adoption_largest.drop(['Population',\n",
    "                                'Household Income',\n",
    "                                'Area (sq mi)',\n",
    "                                'Density',\n",
    "                                'Classification',\n",
    "                                'Vehicles'],\n",
    "                               axis=1,\n",
    "                               inplace=True)\n",
    "urban_ev_adoption_largest\n",
    "\n",
    "# That should give us the exact data we need for a stacked bar chart visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891f855-f3ab-4886-b523-2004c479861d",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "Below, the final results for the state as a whole are calculated as well as for the eight largest rural and eight largest urban counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed4209-b207-4136-a477-d653ada388ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average annual urban registrations: {aggregated_urban[\"Vehicles per 100K\"].mean()}')\n",
    "print(f'Average annual rural registrations: {aggregated_rural[\"Vehicles per 100K\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e35c3e-afa9-4f60-9ccd-8a31224f861d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf2e1ef1-12b9-476a-82b0-e8bdde17c66e",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "We should now have all the datasets required to answer our questions. In order to facilitate analysis, it is likely easiest to create visualizations. This will show trends, by county and also at the summary level by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34de10-d1ac-4c50-9e7a-02531e26c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try plotting the adoption rate for the entire state of EV's\n",
    "# as a line chart, separating out the number of car registrations into rural vs. urban areas\n",
    "#\n",
    "# Rather than just looking at the totals, a more interesting comparison is to look at \n",
    "# The number of cars registered per hundred thousand people, otherwise we will just see\n",
    "# higher numbers for urban regions because they are the majority of the population, when what\n",
    "# we really want are the comparative rates of adoption, so the 'y' axis is effectively\n",
    "# normalized for both urban and rural--a true rate.\n",
    "\n",
    "ax = aggregated_urban['Vehicles per 100K'].plot(xticks=aggregated_rural.index,\n",
    "                                    title='Total California EV Car Registrations, Urban and Rural',\n",
    "                                   )\n",
    "aggregated_rural['Vehicles per 100K'].plot(ax = ax, xticks=aggregated_rural.index)\n",
    "plt.legend([\"Urban EVs Registered\", \"Rural EVs Registered\"])\n",
    "plt.ylabel('Cars Registered per Year per 100K Population')\n",
    "title='California EV Car Registrations, Urban and Rural'\n",
    "\n",
    "plt.savefig('Resources/Car_Registrations_Urban_v_Rural.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828ba57-574a-4a26-812b-1b9a5fcd4d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try plotting the same data, but by county rather than at the summary level\n",
    "# for the entire state. This will probably work best as a stacked bar chart\n",
    "# with the cars per year per 100K population on the 'y' axis, and the individual\n",
    "# counties along the x axis. To keep it from becoming too busy, maybe ten largest\n",
    "# (by population) urban counties vs. ten largest rural counties? That would cover\n",
    "# \n",
    "pivot_rural = pd.pivot_table(data=rural_ev_adoption_largest,\n",
    "                             index=['County'],\n",
    "                             columns=['Year'],\n",
    "                             values='Vehicles per 100K')\n",
    "pivot_urban = pd.pivot_table(data=urban_ev_adoption_largest,\n",
    "                             index=['County'],\n",
    "                             columns=['Year'],\n",
    "                             values='Vehicles per 100K')\n",
    "pivot_rural = pivot_rural.sort_values(by=2022, ignore_index=False, ascending=True)\n",
    "pivot_urban = pivot_urban.sort_values(by=2022, ignore_index=False, ascending=True)\n",
    "\n",
    "# We are going to want two subplots, right next to each other\n",
    "# Any other presentation gets muddled since there is no way to tell\n",
    "# by county name, for example, whether it is urban or rural\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(6)\n",
    "fig.suptitle('EV Adoption by year for Seven Largest Rural and Urban Counties')\n",
    "ax1y1 = pivot_rural[2020].tolist()\n",
    "ax1y2 = pivot_rural[2021].tolist()\n",
    "ax1y3 = pivot_rural[2022].tolist()\n",
    "ax2y1 = pivot_urban[2020].tolist()\n",
    "ax2y2 = pivot_urban[2021].tolist()\n",
    "ax2y3 = pivot_urban[2021].tolist()\n",
    "ax1.set_ylabel('Vehicles Registered per 100K')\n",
    "\n",
    "\n",
    "ax1.bar(pivot_rural.index.tolist(), ax1y1, color='r', label='2020')\n",
    "ax1.bar(pivot_rural.index.tolist(), ax1y2, bottom = ax1y1, color='b', label='2021')\n",
    "ax1.bar(pivot_rural.index.tolist(), ax1y3, bottom = np.add(ax1y1, ax1y2), color='g', label='2022')\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax2.bar(pivot_urban.index.tolist(), ax2y1, color='r', label='2020')\n",
    "ax2.bar(pivot_urban.index.tolist(), ax2y2, bottom = ax2y1, color='b', label='2021')\n",
    "ax2.bar(pivot_urban.index.tolist(), ax2y3, bottom = np.add(ax2y1, ax2y2), color='g', label='2022')\n",
    "ax2.legend(loc=\"upper left\")\n",
    "\n",
    "ax1.tick_params(axis='x', labelrotation=90)\n",
    "ax2.tick_params(axis='x', labelrotation=90)\n",
    "ax1.set_xlabel('Largest Rural Counties')\n",
    "ax2.set_xlabel('Largest Urban Counties')\n",
    "fig.align_xlabels()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Resources/Car_Registrations_Urban_v_Rural_by_County.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f41124-b899-4477-8b83-440af08e8337",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Going into the project, I was expecting to see a large gap in the adoption rate of EV's between urban and rural counties. The expectation was that the longer distances required to get to a public charging station coupled with the longer driving distances in general for residents of rural counties would significantly reduce the number of EV's purchased and operated in rural counties on a per capita basis. That turned out not to be the case. Rural counties have an average of 218 EV car registrations per year per 100,000 residents across the three years for which DMV data were available, while urban counties had an average of about 234 EV car registrations per year per 100,000, only 7% higher than rural counties. In addition, that gap is narrowing with 2022 data almost exactly matching between urban and rural locations in California.\n",
    "\n",
    "In looking at the data for the eight largest counties, both urban and rural, there is one trend to note: adoption rates appear somewhat higher in total over the three years for northern california urban counties than for southern california urban counties. The differences in the rural counties are much smaller with adoption rates being vary similar across the board. \n",
    "\n",
    "There are two significant weaknesses in the datasets that should be pointed out. First, only three years of DMV were available, so extrapolation of current trends into future years would be quite risky. Second, the classification of rural vs. urban may be generally correct, but there are some counties that have significant urban populations--perhaps even mostly urban populations--that are considered \"rural\" simply because they are so large. The most obvious of these is San Diego county. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49204f2f-5ad9-48b2-ae06-1b258d0d7c4f",
   "metadata": {},
   "source": [
    "# Ending of Jared (census_jared.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436bb44-51af-4351-bb46-a9423bda3002",
   "metadata": {},
   "source": [
    "# Beginning of Gina (Ginaupdates.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2cd8f-ac79-49ff-9ddd-a331d012c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# yearly files\n",
    "vehicle_data_2020 = ('vehicle_type_by_zipcode_2020.csv')\n",
    "vehicle_data_2021 = ('vehicle_type_by_zipcode_2021.csv')\n",
    "vehicle_data_2022 = ('vehicle_type_by_zipcode_2022.csv')\n",
    "\n",
    "#census data\n",
    "census_data = ('census_data.csv')\n",
    "\n",
    "# reading each file\n",
    "data_2020 = pd.read_csv(vehicle_data_2020, low_memory=False)\n",
    "data_2021 = pd.read_csv(vehicle_data_2021, low_memory=False)\n",
    "data_2022 = pd.read_csv(vehicle_data_2022, low_memory=False)\n",
    "county_data = pd.read_csv(census_data)\n",
    "\n",
    "# adding a year column\n",
    "data_2020['Year'] = 2020\n",
    "data_2021['Year'] = 2021\n",
    "data_2022['Year'] = 2022\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "merged_data = pd.concat([data_2020, data_2021, data_2022], ignore_index=True)\n",
    "\n",
    "# resetting the index of the DataFrame\n",
    "merged_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_data)\n",
    "\n",
    "\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d6866-ea69-4908-a7fa-fc7decea3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_count = len(merged_data)\n",
    "records_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1ff45-3aa7-4f95-acd2-64b9d141da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_types = merged_data['Fuel'].unique()\n",
    "\n",
    "# Print the unique fuel types in this set\n",
    "print(\"Fuel types:\", fuel_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69e64d-1787-4ac1-89c2-3f7d3cfb5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns for model year, make, and duty\n",
    "merged_data.drop(['Model Year', 'Make', 'Duty'], axis=1, inplace=True)\n",
    "merged_data.rename(columns={'Zip Code': 'Zipcode'}, inplace=True)\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332499e2-7351-4a80-96b9-1d43a04fc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the merged data to a new csv, after the dropped fields\n",
    "merged_data.to_csv('merged_data_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce8815e-ce8c-4019-be0c-efd3048ae357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the vehicle data to the zip and county data \n",
    "census_data = ('census_data.csv')\n",
    "vehicle_data_updt = ('merged_data_modified.csv')\n",
    "\n",
    "# reading each file\n",
    "county_data = pd.read_csv(census_data, dtype={\n",
    "    'Zipcode': 'object',\n",
    "    'county': 'object'})\n",
    "all_vehicle_data = pd.read_csv(vehicle_data_updt, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48d30e-e492-4aa4-9898-5fd9913a3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_data.drop(['Unnamed: 0', 'Population', 'Household Income', 'state_fips', 'state', 'state_abbr', 'city', 'Year'], axis=1, inplace=True)\n",
    "county_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378b790-61de-45ec-a3bf-9c1fee335abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on the 'Zip Code' column\n",
    "merged_data_all = pd.merge(all_vehicle_data, county_data, on='Zipcode', how='left')\n",
    "\n",
    "# Display the merged dataframe\n",
    "merged_data_all.head()\n",
    "merged_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd278467-4071-45e2-8c3f-8bfdc28c13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_data_all['Year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6855d3b7-63c1-410f-a808-b5bb6f2e3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_county = 'Alameda'\n",
    "desired_year = 2022\n",
    "\n",
    "# filtering dataframe for the desired county and year\n",
    "county_year_data = merged_data_all.loc[(merged_data_all['county'] == desired_county) & (merged_data_all['Year'] == desired_year)]\n",
    "county_year_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12745ddd-518b-41c1-a943-777c97c0f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the data for 2020 with counties\n",
    "fuel_types_2020 = merged_data_all[merged_data_all['Year'] == 2020]\n",
    "fuel_types_2020 = fuel_types_2020.groupby(['county','Fuel', 'Year']).agg({'Vehicles': 'count'}).reset_index()\n",
    "fuel_types_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de6444-4f9e-42b7-bdf5-10d81cd2bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vehicle_counts_2020 = fuel_types_2020.groupby('Fuel')['Vehicles'].sum().reset_index()\n",
    "\n",
    "total_vehicle_counts_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59714b-76d1-4291-9c9c-de55aec5358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the data for 2020 with counties\n",
    "fuel_types_2021 = merged_data_all[merged_data_all['Year'] == 2021]\n",
    "fuel_types_2021 = fuel_types_2021.groupby(['county','Fuel', 'Year']).agg({'Vehicles': 'count'}).reset_index()\n",
    "fuel_types_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1c4c0-61ea-4929-8f06-bf31c99b4b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vehicle_counts_2021 = fuel_types_2021.groupby('Fuel')['Vehicles'].sum().reset_index()\n",
    "\n",
    "total_vehicle_counts_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4090d67-e12e-4a30-8fa7-18973f5abdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_types_2022 = merged_data_all[merged_data_all['Year'] == 2022]\n",
    "fuel_types_2022 = fuel_types_2022.groupby(['county','Fuel', 'Year']).agg({'Vehicles': 'count'}).reset_index()\n",
    "fuel_types_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64545b9e-2935-41d4-baef-08168561168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vehicle_counts_2022 = fuel_types_2022.groupby('Fuel')['Vehicles'].sum().reset_index()\n",
    "\n",
    "total_vehicle_counts_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb04e28-faab-43df-ad18-15065ecdabce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for 2020\n",
    "fuel_types_2020 = {\n",
    "    'Battery Electric': 76020,\n",
    "    'Diesel and Diesel Hybrid': 295075,\n",
    "    'Flex-Fuel': 259780,\n",
    "    'Gasoline': 1586575,\n",
    "    'Hybrid Gasoline': 201905,\n",
    "    'Hydrogen Fuel Cell': 8415,\n",
    "    'Natural Gas': 26260,\n",
    "    'Other': 7770,\n",
    "    'Plug-in Hybrid': 79645\n",
    "}\n",
    "\n",
    "# Data for 2021\n",
    "fuel_types_2021 = {\n",
    "    'Battery Electric': 85820,\n",
    "    'Diesel and Diesel Hybrid': 331395,\n",
    "    'Flex-Fuel': 339580,\n",
    "    'Gasoline': 1713775,\n",
    "    'Hybrid Gasoline': 211950,\n",
    "    'Hydrogen Fuel Cell': 10490,\n",
    "    'Natural Gas': 16750,\n",
    "    'Other': 47445,\n",
    "    'Plug-in Hybrid': 96090\n",
    "}\n",
    "\n",
    "# Data for 2022\n",
    "fuel_types_2022 = {\n",
    "    'Battery Electric': 106290,\n",
    "    'Diesel and Diesel Hybrid': 367745,\n",
    "    'Flex-Fuel': 350785,\n",
    "    'Gasoline': 1834675,\n",
    "    'Hybrid Gasoline': 235670,\n",
    "    'Hydrogen Fuel Cell': 13705,\n",
    "    'Natural Gas': 29005,\n",
    "    'Other': 6280,\n",
    "    'Plug-in Hybrid': 110320\n",
    "}\n",
    "\n",
    "# Extract fuel types and vehicle totals\n",
    "fuel_types = list(fuel_types_2020.keys())\n",
    "vehicles_2020 = list(fuel_types_2020.values())\n",
    "vehicles_2021 = list(fuel_types_2021.values())\n",
    "vehicles_2022 = list(fuel_types_2022.values())\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(fuel_types, vehicles_2020, label='2020')\n",
    "plt.plot(fuel_types, vehicles_2021, label='2021')\n",
    "plt.plot(fuel_types, vehicles_2022, label='2022')\n",
    "\n",
    "# Customizing the plot\n",
    "plt.xlabel('Fuel Type')\n",
    "plt.ylabel('Vehicle Total')\n",
    "plt.title('Vehicle Total by Fuel Type (2020-2022)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9346dcd3-020a-4aef-aee8-584b52e314db",
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_electric_data = merged_data_all[merged_data_all['Fuel'] == 'Battery Electric']\n",
    "#battery_electric_data = battery_electric_data.drop_duplicates()\n",
    "battery_electric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c2123-41a2-4fba-ad39-b1c149fb9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the DataFrame by 'Zip Code' to calculate the sum of 'Vehicles' for each zip code\n",
    "battery_electric_totals = battery_electric_data.groupby(['county','Fuel', 'Year']).agg({'Vehicles': 'count'}).reset_index()\n",
    "\n",
    "battery_electric_totals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819759f2-c208-431d-b38a-0da79965bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping two counties: Sierra and Modoc, total counties will be 56\n",
    "\n",
    "# filtering the DataFrame by ‘Zip Code’ to calculate the sum of ‘Vehicles’ for each zip code\n",
    "battery_electric_totals = battery_electric_data.groupby(['county','Fuel', 'Year']).agg({'Vehicles': 'count'}).reset_index()\n",
    "# We also need to drop any counties where we don’t have all three years of data...\n",
    "# To do that, we want to find a list of counties\n",
    "keepcounty = battery_electric_totals.groupby('county').count()\n",
    "keepcounty = keepcounty.loc[keepcounty['Fuel'] == 3]\n",
    "# Now we can delete any rows from multi_census_pd\n",
    "# Where the Zipcode is not in the ‘keepzip’ file\n",
    "battery_electric_totals = battery_electric_totals[battery_electric_totals['county'].isin(keepcounty.index)]\n",
    "# totals for each zip code\n",
    "battery_electric_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3144b-b6bc-450f-9541-0eb622487c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the merged data to a new csv, after the dropped fields\n",
    "battery_electric_totals.to_csv('battery_electric_totals.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92a2c8-45ed-4cc6-9891-e5fc0d67a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_counties = battery_electric_totals['county'].nunique()\n",
    "num_counties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b81ac-47ce-4399-8ea6-08186a976e61",
   "metadata": {},
   "source": [
    "BAR CHART FOR NUMBER OF EV PER COUNTY AND YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d564fc5-3c6e-4470-a644-83949961b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = battery_electric_totals.pivot(index='county', columns='Year', values='Vehicles')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Define x positions for bars\n",
    "x = np.arange(len(pivot_df.index))\n",
    "\n",
    "# Width of each bar\n",
    "width = 0.25\n",
    "\n",
    "# Plot bars for each year\n",
    "plt.bar(x - width, pivot_df[2020], width, label='2020')\n",
    "plt.bar(x, pivot_df[2021], width, label='2021')\n",
    "plt.bar(x + width, pivot_df[2022], width, label='2022')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('# of Electric Vehicles')\n",
    "plt.title('Number of Electric Vehicles per County and Year')\n",
    "plt.xticks(x, pivot_df.index, rotation=90)\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2a59c-8c31-47c4-bf64-f43b59b83431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Calculate the percentage increase from 2020 to 2021\n",
    "increase_2021 = ((pivot_df[2021] - pivot_df[2020]) / pivot_df[2020]) * 100\n",
    "\n",
    "# Calculate the percentage increase from 2021 to 2022\n",
    "increase_2022 = ((pivot_df[2022] - pivot_df[2021]) / pivot_df[2021]) * 100\n",
    "\n",
    "# Combine the increase rates into a DataFrame\n",
    "increase_rates = pd.DataFrame({'Increase Rate 2021': increase_2021, 'Increase Rate 2022': increase_2022})\n",
    "\n",
    "# Display the increase rates\n",
    "print(\"Increase Rates:\")\n",
    "increase_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da00af9-80b3-47d1-815b-8459a6566940",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_by_year = battery_electric_totals.groupby('Year')['Vehicles'].sum()\n",
    "\n",
    "# Display the total number of battery electric vehicles for each year\n",
    "total_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a720d0-18e4-4a80-a379-165eb833ec9a",
   "metadata": {},
   "source": [
    "# Ending of Gina\n",
    "\n",
    "Going into the project, I was expecting to see a large gap in the adoption rate of EV's between urban and rural counties. The expectation was that the longer distances required to get to a public charging station coupled with the longer driving distances in general for residents of rural counties would significantly reduce the number of EV's purchased and operated in rural counties on a per capita basis. That turned out not to be the case. Rural counties have an average of 218 EV car registrations per year per 100,000 residents across the three years for which DMV data were available, while urban counties had an average of about 2Going into the project, I was expecting to see a large gap in the adoption rate of EV's between urban and rural counties. The expectation was that the longer distances required to get to a public charging station coupled with the longer driving distances in general for residents of rural counties would significantly reduce the number of EV's purchased and operated in rural counties on a per capita basis. That turned out not to be the case. Rural counties have an average of 218 EV car registrations per year per 100,000 residents across the three years for which DMV data were available, while urban counties had an average of about 234 EV car registrations per year per 100,000, only 7% higher than rural counties. In addition, that gap is narrowing with 2022 data almost exactly matching between urban and rural locations in California.34 EV car registrations per year per 100,000, only 7% higher than rural counties. In addition, that gap is narrowing with 2022 data almost exactly matching between urban and rural locations in California.\n",
    "\n",
    "In looking at the data for the eight largest counties, both urban and rural, there is one trend to note: adoption rates appear somewhat higher in total over the three years for northern california urban counties than for southern california urban counties. The differences in the rural counties are much smaller with adoption rates being vary similar across the board. \n",
    "\n",
    "There are two significant weaknesses in the datasets that should be pointed out. First, only three years of DMV were available, so extrapolation of current trends into future years would be quite risky. Second, the classification of rural vs. urban may be generally correct, but there are some counties that have significant urban populations--perhaps even mostly urban populations--that are considered \"rural\" simply because they are so large. The most obvious of these is San Diego county. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302d981-e93f-4c0b-8fda-f730b3134583",
   "metadata": {},
   "source": [
    "# Beginning of Aram (EV_Chargers.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d50834-70f1-492e-b22e-9a67e2327269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "\n",
    "#  Data\n",
    "EV_Chargers_Path = \"EV_Chargers1.csv\"\n",
    "\n",
    "# Read the data\n",
    "EV_Chargers_data = pd.read_csv(EV_Chargers_Path)\n",
    "\n",
    "# Preview data\n",
    "EV_Chargers_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be97f74-2a5b-49a9-b07c-43b234f7b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data in the form of a list of lists\n",
    "data = [\n",
    "    ['Alameda', 5893, 4624, 4504, 4430, 4282, 5139, 5051, 3697, 3625, 3560, 3544, 3353, 3082, 2990],\n",
    "    ['Alpine', 12, 10, 10, 6, 16, 16, 18, 14, 15, 15, 15, 15, 13, 12],\n",
    "    ['Amador', 34, 34, 34, 34, 33, 33, 33, 39, 40, 40, 40, 40, 30, 29],\n",
    "    ['Butte', 157, 149, 147, 146, 139, 158, 132, 94, 92, 91, 82, 76, 76, 74],\n",
    "    ['Calaveras', 23, 23, 21, 25, 23, 23, 21, 21, 21, 19, 19, 7, 7, 7],\n",
    "    ['Colusa', 37, 36, 36, 34, 34, 36, 36, 38, 34, 30, 28, 28, 28, 28],\n",
    "    ['Contra Costa', 1632, 1734, 1674, 1503, 1495, 1699, 1715, 1451, 1483, 1461, 1455, 1355, 1325, 1068],\n",
    "    ['Del Norte', 46, 47, 47, 39, 39, 32, 32, 29, 29, 25, 25, 30, 30, 30],\n",
    "    ['El Dorado', 258, 214, 202, 189, 194, 193, 173, 179, 181, 177, 167, 173, 160, 150],\n",
    "    ['Fresno', 1292, 1313, 1373, 1291, 1158, 1321, 1311, 1133, 1143, 1127, 1092, 921, 779, 684],\n",
    "    ['Glenn', 8, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
    "    ['Humboldt', 157, 157, 157, 154, 150, 148, 145, 150, 142, 134, 124, 112, 114, 105],\n",
    "    ['Imperial', 52, 50, 50, 49, 45, 43, 35, 31, 33, 33, 33, 27, 27, 15],\n",
    "    ['Inyo', 83, 54, 52, 48, 49, 49, 41, 42, 39, 39, 35, 37, 23, 23],\n",
    "    ['Kern', 832, 797, 721, 691, 646, 629, 631, 416, 359, 306, 298, 279, 279, 241],\n",
    "    ['Kings', 431, 419, 410, 410, 176, 168, 160, 204, 148, 147, 147, 144, 140, 122],\n",
    "    ['Lake', 18, 17, 14, 14, 15, 15, 14, 14, 17, 17, 15, 15, 15, 10],\n",
    "    ['Lassen', 16, 16, 16, 16, 16, 16, 13, 13, 14, 6, 6, 5, 5, 4],\n",
    "    ['Los Angeles', 31569, 29433, 29051, 27015, 25685, 24615, 23903, 20950, 20520, 20193, 19872, 19236, 18509, 16770],\n",
    "    ['Madera', 203, 202, 203, 190, 161, 152, 147, 130, 122, 121, 121, 113, 89, 84],\n",
    "    ['Marin', 1020, 1082, 1048, 1027, 933, 1052, 1037, 739, 734, 730, 728, 706, 684, 629],\n",
    "    ['Mariposa', 62, 59, 60, 46, 33, 45, 35, 24, 30, 16, 16, 16, 16, 16],\n",
    "    ['Mendocino', 229, 214, 203, 186, 200, 162, 158, 160, 158, 158, 146, 144, 129, 110],\n",
    "    ['Merced', 182, 155, 124, 135, 177, 134, 139, 125, 142, 142, 138, 130, 114, 94],\n",
    "    ['Modoc', 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 4, 4, 4, 4],\n",
    "    ['Mono', 52, 38, 38, 38, 38, 37, 37, 32, 32, 32, 32, 32, 31, 31],\n",
    "    ['Monterey', 491, 480, 487, 424, 394, 400, 383, 452, 425, 431, 424, 422, 360, 348],\n",
    "    ['Napa', 478, 442, 433, 396, 391, 403, 393, 393, 390, 388, 386, 374, 348, 316],\n",
    "    ['Nevada', 149, 144, 144, 169, 161, 152, 152, 116, 89, 88, 88, 93, 88, 86],\n",
    "    ['Orange', 6771, 6002, 5797, 5383, 5214, 5189, 5003, 5852, 5657, 5477, 5381, 5242, 4886, 4799],\n",
    "    ['Placer', 622, 522, 518, 455, 425, 448, 424, 419, 402, 365, 361, 351, 339, 305],\n",
    "    ['Plumas', 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 5, 5],\n",
    "    ['Riverside', 1835, 1835, 1745, 1635, 1508, 1493, 1441, 1548, 1495, 1441, 1422, 1464, 1360, 1306],\n",
    "    ['Sacramento', 2253, 2205, 2149, 2040, 1756, 1839, 1765, 1813, 1836, 1852, 1850, 1777, 1765, 1438],\n",
    "    ['San Benito', 27, 29, 28, 45, 43, 47, 47, 47, 49, 47, 47, 50, 42, 44],\n",
    "    ['San Bernardino', 1957, 1841, 1767, 1682, 1615, 1560, 1424, 1367, 1478, 1415, 1395, 1338, 1297, 999],\n",
    "    ['San Diego', 8583, 8094, 7960, 7735, 7358, 7074, 6551, 10080, 7278, 7199, 7170, 6874, 6760, 6073],\n",
    "    ['San Francisco', 2431, 2070, 2002, 1952, 1436, 1575, 1519, 1630, 1840, 1671, 1609, 1505, 1384, 1264],\n",
    "    ['San Joaquin', 825, 728, 680, 632, 612, 596, 565, 442, 407, 402, 397, 389, 326, 306],\n",
    "    ['San Luis Obispo', 777, 705, 694, 650, 616, 640, 638, 566, 513, 513, 493, 493, 486, 442],\n",
    "    ['San Mateo', 5533, 4798, 4619, 4557, 4436, 4799, 4688, 4511, 4701, 4459, 4282, 4070, 3758, 3617],\n",
    "    ['Santa Barbara', 648, 526, 566, 512, 504, 515, 480, 557, 522, 492, 499, 494, 461, 437],\n",
    "    ['Santa Clara', 20220, 18193, 17865, 17621, 16227, 16981, 16831, 15987, 16498, 16202, 16119, 15406, 14913, 14164],\n",
    "    ['Santa Cruz', 359, 369, 356, 359, 345, 356, 333, 307, 306, 300, 302, 281, 262, 250],\n",
    "    ['Shasta', 227, 179, 174, 153, 138, 105, 90, 86, 92, 93, 93, 96, 94, 57],\n",
    "    ['Sierra', 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    ['Siskiyou', 77, 69, 68, 67, 67, 68, 68, 72, 68, 67, 56, 63, 63, 55],\n",
    "    ['Solano', 608, 578, 560, 482, 473, 509, 501, 471, 421, 421, 394, 372, 362, 369],\n",
    "    ['Sonoma', 902, 871, 845, 816, 794, 840, 765, 794, 803, 791, 789, 743, 695, 670],\n",
    "    ['Stanislaus', 249, 202, 178, 188, 171, 158, 149, 151, 158, 150, 151, 145, 145, 122],\n",
    "    ['Sutter', 35, 31, 24, 22, 27, 24, 24, 27, 33, 31, 31, 31, 23, 20],\n",
    "    ['Tehama', 94, 91, 91, 87, 91, 80, 66, 35, 31, 30, 31, 32, 32, 32],\n",
    "    ['Trinity', 15, 12, 14, 14, 14, 14, 14, 6, 6, 6, 6, 8, 8, 4],\n",
    "    ['Tulare', 291, 275, 279, 231, 212, 160, 154, 123, 124, 119, 108, 103, 85, 76],\n",
    "    ['Tuolumne', 55, 54, 54, 58, 60, 52, 52, 78, 54, 50, 50, 47, 47, 45],\n",
    "    ['Ventura', 930, 875, 870, 858, 810, 821, 273, 14, 11, 11, 11, 11, 13, 749],\n",
    "    ['Yolo', 468, 432, 427, 412, 398, 428, 679, 894, 894, 893, 892, 845, 868, 264],\n",
    "    ['Yuba', 69, 80, 79, 75, 59, 60, 299, 394, 388, 386, 386, 324, 328, 14],\n",
    "    ['Unknown', 3368, 807, 807, 807, 1868, 16, 41, 32, 16, 16, 16, 16, 16, 16]\n",
    "]\n",
    "\n",
    "# Columns for the DataFrame\n",
    "columns = ['County', 'Q4 2023', 'Q3 2023', 'Q2 2023', 'Q1 2023', 'Q4 2022', 'Q3 2022', 'Q2 2022', \n",
    "           'Q1 2022', 'Q4 2021', 'Q3 2021', 'Q2 2021', 'Q1 2021', 'Q4 2020', 'Q3 2020']\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Print \n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea2ad3-4019-4d42-8003-53fd0fd2246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(df['County'], df['Q4 2023'], color='blue', label='Q4 2023')\n",
    "plt.scatter(df['County'], df['Q3 2023'], color='red', label='Q3 2023')\n",
    "plt.scatter(df['County'], df['Q2 2023'], color='green', label='Q2 2023')\n",
    "plt.scatter(df['County'], df['Q1 2023'], color='orange', label='Q1 2023')\n",
    "plt.scatter(df['County'], df['Q4 2022'], color='purple', label='Q4 2022')\n",
    "plt.scatter(df['County'], df['Q3 2022'], color='cyan', label='Q3 2022')\n",
    "plt.scatter(df['County'], df['Q2 2022'], color='magenta', label='Q2 2022')\n",
    "plt.scatter(df['County'], df['Q1 2022'], color='yellow', label='Q1 2022')\n",
    "plt.scatter(df['County'], df['Q4 2021'], color='black', label='Q4 2021')\n",
    "plt.scatter(df['County'], df['Q3 2021'], color='brown', label='Q3 2021')\n",
    "plt.scatter(df['County'], df['Q2 2021'], color='pink', label='Q2 2021')\n",
    "plt.scatter(df['County'], df['Q1 2021'], color='gray', label='Q1 2021')\n",
    "plt.scatter(df['County'], df['Q4 2020'], color='olive', label='Q4 2020')\n",
    "plt.scatter(df['County'], df['Q3 2020'], color='cyan', label='Q3 2020')\n",
    "\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('EV Charging Stations')\n",
    "plt.title('EV Charging Station Adaptation by Year')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(df['County'], df['Q4 2023'], color='blue', label='Q4 2023')\n",
    "plt.bar(df['County'], df['Q3 2023'], color='red', label='Q3 2023', alpha=0.7)\n",
    "plt.bar(df['County'], df['Q2 2023'], color='green', label='Q2 2023', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q1 2023'], color='orange', label='Q1 2023', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q4 2022'], color='purple', label='Q4 2022', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q3 2022'], color='cyan', label='Q3 2022', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q2 2022'], color='magenta', label='Q2 2022', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q1 2022'], color='yellow', label='Q1 2022', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q4 2021'], color='black', label='Q4 2021', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q3 2021'], color='brown', label='Q3 2021', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q2 2021'], color='pink', label='Q2 2021', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q1 2021'], color='gray', label='Q1 2021', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q4 2020'], color='olive', label='Q4 2020', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q3 2020'], color='cyan', label='Q3 2020', alpha=0.5)\n",
    "\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('EV Charging Stations')\n",
    "plt.title('EV Charging Station Adaptation by Year')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b46640-0ad9-4013-a937-5f9aab07bc18",
   "metadata": {},
   "source": [
    "# Ending of Aram (EV_Chargers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a08a6c-23fc-4a64-9732-0fd9b189c44d",
   "metadata": {},
   "source": [
    "# Beginning of Aram (Charging_Stations_by_County.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a49a3a-1845-40af-b4ce-236f544e9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "\n",
    "#  Data\n",
    "EV_Chargers_Path = \"EV_Chargers1.csv\"\n",
    "\n",
    "# Read the data\n",
    "EV_Chargers_data = pd.read_csv(EV_Chargers_Path)\n",
    "\n",
    "# Preview data\n",
    "EV_Chargers_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d46aa-b61f-412a-889e-9f960f44ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data in the form of a list of lists\n",
    "data = [\n",
    "    ['Alameda', 5893, 4624, 4504, 4430, 4282, 5139, 5051, 3697, 3625, 3560, 3544, 3353, 3082, 2990],\n",
    "    ['Alpine', 12, 10, 10, 6, 16, 16, 18, 14, 15, 15, 15, 15, 13, 12],\n",
    "    ['Amador', 34, 34, 34, 34, 33, 33, 33, 39, 40, 40, 40, 40, 30, 29],\n",
    "    ['Butte', 157, 149, 147, 146, 139, 158, 132, 94, 92, 91, 82, 76, 76, 74],\n",
    "    ['Calaveras', 23, 23, 21, 25, 23, 23, 21, 21, 21, 19, 19, 7, 7, 7],\n",
    "    ['Colusa', 37, 36, 36, 34, 34, 36, 36, 38, 34, 30, 28, 28, 28, 28],\n",
    "    ['Contra Costa', 1632, 1734, 1674, 1503, 1495, 1699, 1715, 1451, 1483, 1461, 1455, 1355, 1325, 1068],\n",
    "    ['Del Norte', 46, 47, 47, 39, 39, 32, 32, 29, 29, 25, 25, 30, 30, 30],\n",
    "    ['El Dorado', 258, 214, 202, 189, 194, 193, 173, 179, 181, 177, 167, 173, 160, 150],\n",
    "    ['Fresno', 1292, 1313, 1373, 1291, 1158, 1321, 1311, 1133, 1143, 1127, 1092, 921, 779, 684],\n",
    "    ['Glenn', 8, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
    "    ['Humboldt', 157, 157, 157, 154, 150, 148, 145, 150, 142, 134, 124, 112, 114, 105],\n",
    "    ['Imperial', 52, 50, 50, 49, 45, 43, 35, 31, 33, 33, 33, 27, 27, 15],\n",
    "    ['Inyo', 83, 54, 52, 48, 49, 49, 41, 42, 39, 39, 35, 37, 23, 23],\n",
    "    ['Kern', 832, 797, 721, 691, 646, 629, 631, 416, 359, 306, 298, 279, 279, 241],\n",
    "    ['Kings', 431, 419, 410, 410, 176, 168, 160, 204, 148, 147, 147, 144, 140, 122],\n",
    "    ['Lake', 18, 17, 14, 14, 15, 15, 14, 14, 17, 17, 15, 15, 15, 10],\n",
    "    ['Lassen', 16, 16, 16, 16, 16, 16, 13, 13, 14, 6, 6, 5, 5, 4],\n",
    "    ['Los Angeles', 31569, 29433, 29051, 27015, 25685, 24615, 23903, 20950, 20520, 20193, 19872, 19236, 18509, 16770],\n",
    "    ['Madera', 203, 202, 203, 190, 161, 152, 147, 130, 122, 121, 121, 113, 89, 84],\n",
    "    ['Marin', 1020, 1082, 1048, 1027, 933, 1052, 1037, 739, 734, 730, 728, 706, 684, 629],\n",
    "    ['Mariposa', 62, 59, 60, 46, 33, 45, 35, 24, 30, 16, 16, 16, 16, 16],\n",
    "    ['Mendocino', 229, 214, 203, 186, 200, 162, 158, 160, 158, 158, 146, 144, 129, 110],\n",
    "    ['Merced', 182, 155, 124, 135, 177, 134, 139, 125, 142, 142, 138, 130, 114, 94],\n",
    "    ['Modoc', 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 4, 4, 4, 4],\n",
    "    ['Mono', 52, 38, 38, 38, 38, 37, 37, 32, 32, 32, 32, 32, 31, 31],\n",
    "    ['Monterey', 491, 480, 487, 424, 394, 400, 383, 452, 425, 431, 424, 422, 360, 348],\n",
    "    ['Napa', 478, 442, 433, 396, 391, 403, 393, 393, 390, 388, 386, 374, 348, 316],\n",
    "    ['Nevada', 149, 144, 144, 169, 161, 152, 152, 116, 89, 88, 88, 93, 88, 86],\n",
    "    ['Orange', 6771, 6002, 5797, 5383, 5214, 5189, 5003, 5852, 5657, 5477, 5381, 5242, 4886, 4799],\n",
    "    ['Placer', 622, 522, 518, 455, 425, 448, 424, 419, 402, 365, 361, 351, 339, 305],\n",
    "    ['Plumas', 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 5, 5],\n",
    "    ['Riverside', 1835, 1835, 1745, 1635, 1508, 1493, 1441, 1548, 1495, 1441, 1422, 1464, 1360, 1306],\n",
    "    ['Sacramento', 2253, 2205, 2149, 2040, 1756, 1839, 1765, 1813, 1836, 1852, 1850, 1777, 1765, 1438],\n",
    "    ['San Benito', 27, 29, 28, 45, 43, 47, 47, 47, 49, 47, 47, 50, 42, 44],\n",
    "    ['San Bernardino', 1957, 1841, 1767, 1682, 1615, 1560, 1424, 1367, 1478, 1415, 1395, 1338, 1297, 999],\n",
    "    ['San Diego', 8583, 8094, 7960, 7735, 7358, 7074, 6551, 10080, 7278, 7199, 7170, 6874, 6760, 6073],\n",
    "    ['San Francisco', 2431, 2070, 2002, 1952, 1436, 1575, 1519, 1630, 1840, 1671, 1609, 1505, 1384, 1264],\n",
    "    ['San Joaquin', 825, 728, 680, 632, 612, 596, 565, 442, 407, 402, 397, 389, 326, 306],\n",
    "    ['San Luis Obispo', 777, 705, 694, 650, 616, 640, 638, 566, 513, 513, 493, 493, 486, 442],\n",
    "    ['San Mateo', 5533, 4798, 4619, 4557, 4436, 4799, 4688, 4511, 4701, 4459, 4282, 4070, 3758, 3617],\n",
    "    ['Santa Barbara', 648, 526, 566, 512, 504, 515, 480, 557, 522, 492, 499, 494, 461, 437],\n",
    "    ['Santa Clara', 20220, 18193, 17865, 17621, 16227, 16981, 16831, 15987, 16498, 16202, 16119, 15406, 14913, 14164],\n",
    "    ['Santa Cruz', 359, 369, 356, 359, 345, 356, 333, 307, 306, 300, 302, 281, 262, 250],\n",
    "    ['Shasta', 227, 179, 174, 153, 138, 105, 90, 86, 92, 93, 93, 96, 94, 57],\n",
    "    ['Sierra', 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    ['Siskiyou', 77, 69, 68, 67, 67, 68, 68, 72, 68, 67, 56, 63, 63, 55],\n",
    "    ['Solano', 608, 578, 560, 482, 473, 509, 501, 471, 421, 421, 394, 372, 362, 369],\n",
    "    ['Sonoma', 902, 871, 845, 816, 794, 840, 765, 794, 803, 791, 789, 743, 695, 670],\n",
    "    ['Stanislaus', 249, 202, 178, 188, 171, 158, 149, 151, 158, 150, 151, 145, 145, 122],\n",
    "    ['Sutter', 35, 31, 24, 22, 27, 24, 24, 27, 33, 31, 31, 31, 23, 20],\n",
    "    ['Tehama', 94, 91, 91, 87, 91, 80, 66, 35, 31, 30, 31, 32, 32, 32],\n",
    "    ['Trinity', 15, 12, 14, 14, 14, 14, 14, 6, 6, 6, 6, 8, 8, 4],\n",
    "    ['Tulare', 291, 275, 279, 231, 212, 160, 154, 123, 124, 119, 108, 103, 85, 76],\n",
    "    ['Tuolumne', 55, 54, 54, 58, 60, 52, 52, 78, 54, 50, 50, 47, 47, 45],\n",
    "    ['Ventura', 930, 875, 870, 858, 810, 821, 273, 14, 11, 11, 11, 11, 13, 749],\n",
    "    ['Yolo', 468, 432, 427, 412, 398, 428, 679, 894, 894, 893, 892, 845, 868, 264],\n",
    "    ['Yuba', 69, 80, 79, 75, 59, 60, 299, 394, 388, 386, 386, 324, 328, 14],\n",
    "]\n",
    "\n",
    "# Columns for the DataFrame\n",
    "columns = ['County', 'Q4 2023', 'Q3 2023', 'Q2 2023', 'Q1 2023', 'Q4 2022', 'Q3 2022', 'Q2 2022', \n",
    "           'Q1 2022', 'Q4 2021', 'Q3 2021', 'Q2 2021', 'Q1 2021', 'Q4 2020', 'Q3 2020']\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Print \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc610f1-339c-4895-b41c-a3ec5b2bc635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(df['County'], df['Q4 2023'], color='blue', label='Q4 2023')\n",
    "plt.scatter(df['County'], df['Q3 2023'], color='red', label='Q3 2023')\n",
    "plt.scatter(df['County'], df['Q2 2023'], color='green', label='Q2 2023')\n",
    "plt.scatter(df['County'], df['Q1 2023'], color='orange', label='Q1 2023')\n",
    "plt.scatter(df['County'], df['Q4 2022'], color='purple', label='Q4 2022')\n",
    "plt.scatter(df['County'], df['Q3 2022'], color='cyan', label='Q3 2022')\n",
    "plt.scatter(df['County'], df['Q2 2022'], color='magenta', label='Q2 2022')\n",
    "plt.scatter(df['County'], df['Q1 2022'], color='yellow', label='Q1 2022')\n",
    "plt.scatter(df['County'], df['Q4 2021'], color='black', label='Q4 2021')\n",
    "plt.scatter(df['County'], df['Q3 2021'], color='brown', label='Q3 2021')\n",
    "plt.scatter(df['County'], df['Q2 2021'], color='pink', label='Q2 2021')\n",
    "plt.scatter(df['County'], df['Q1 2021'], color='gray', label='Q1 2021')\n",
    "plt.scatter(df['County'], df['Q4 2020'], color='olive', label='Q4 2020')\n",
    "plt.scatter(df['County'], df['Q3 2020'], color='cyan', label='Q3 2020')\n",
    "\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('EV Charging Stations')\n",
    "plt.title('EV Charging Station Adaptation by Year')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(df['County'], df['Q4 2023'], color='blue', label='Q4 2023')\n",
    "plt.bar(df['County'], df['Q3 2023'], color='red', label='Q3 2023', alpha=0.7)\n",
    "plt.bar(df['County'], df['Q2 2023'], color='green', label='Q2 2023', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q1 2023'], color='orange', label='Q1 2023', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q4 2022'], color='purple', label='Q4 2022', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q3 2022'], color='cyan', label='Q3 2022', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q2 2022'], color='magenta', label='Q2 2022', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q1 2022'], color='yellow', label='Q1 2022', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q4 2021'], color='black', label='Q4 2021', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q3 2021'], color='brown', label='Q3 2021', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q2 2021'], color='pink', label='Q2 2021', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q1 2021'], color='gray', label='Q1 2021', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q4 2020'], color='olive', label='Q4 2020', alpha=0.5)\n",
    "plt.bar(df['County'], df['Q3 2020'], color='cyan', label='Q3 2020', alpha=0.5)\n",
    "\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('EV Charging Stations')\n",
    "plt.title('EV Charging Station Adaptation by Year')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618c179-6b83-4264-a9a4-a2e13dc4bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Selecting a subset of counties for demonstration\n",
    "counties_to_plot = ['Los Angeles', 'San Francisco', 'Orange', 'Alameda', 'San Diego', 'Santa Clara', 'San Mateo']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for county in counties_to_plot:\n",
    "    county_data = df[df['County'] == county].iloc[:, 1:]  # Exclude 'County' column\n",
    "    county_data = county_data.T.reset_index()\n",
    "    county_data.columns = ['Quarter', 'EV Charging Stations']\n",
    "    \n",
    "    plt.plot(county_data['Quarter'], county_data['EV Charging Stations'], marker='o', label=county)\n",
    "\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('EV Charging Stations')\n",
    "plt.title('EV Charging Station Trend by County')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d7b0d-ee83-4d7c-8150-3e8081a0c275",
   "metadata": {},
   "source": [
    "# Beginning of Mo (gas_price.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252814c2-f9a4-4737-bf45-ef2bb702e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214046b2-cc74-42f2-93c4-11eacfdd9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '4k9wboAV8W8ZdRVGqA9uIR:4LYhjC1Sx8VVuzdgg7P2uu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0a544-eb36-43d2-81e4-7e1f4f28f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c17e23-9d9b-48cf-8f4c-e7db8f9a8524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://collectapi.com/api/gasPrice/gas-prices-api?tab=pricing\"\n",
    "url = \"https://api.collectapi.com/gasPrice/stateUsaPrice?state=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db20132-2a05-4ba5-9f44-4b3cfd4dc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'content-type': \"application/json\",\n",
    "    'authorization': \"apikey 3NHVADT5KuNLk3ZMn0THtC:2pmqCh12nXGVUWBbdn6wFy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcad19-c2e6-4c5d-8548-411edaf35fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb37424-6ebe-4deb-9672-188505b2ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url + \"CA\", headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09fff8-7add-48d4-bacc-fcb3fe1ec1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb565bcd-b4cf-4e23-a062-040354ef86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "\n",
    "conn = http.client.HTTPSConnection(\"api.collectapi.com\")\n",
    "\n",
    "headers = {\n",
    "    'content-type': \"application/json\",\n",
    "    'authorization': \"apikey 3NHVADT5KuNLk3ZMn0THtC:2pmqCh12nXGVUWBbdn6wFy\"\n",
    "    }\n",
    "\n",
    "conn.request(\"GET\", \"/gasPrice/stateUsaPrice?state=WA\", headers=headers)\n",
    "\n",
    "res = conn.getresponse()\n",
    "data = res.read()\n",
    "\n",
    "print(data.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5958072a-ff56-47ca-ad29-8e8ded0ad366",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8194d9b-fa6f-4571-84d7-2c7ac9e9980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = \"&apikey=\" + api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58af894-5ab5-4059-bb72-4d073c4c4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9533cd5-f6ad-4455-becb-29029d96f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3d2c4-c20a-40dc-a250-4d1f56db5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'currency': 'usd', 'gasoline': '4.834', 'midGrade': '5.059', 'premium': '5.246', 'diesel': '5.620', 'name': 'Bakersfield', 'lowerName': 'bakersfield'}, {'currency': 'usd', 'gasoline': '4.817', 'midGrade': '5.035', 'premium': '5.156', 'diesel': '5.130', 'name': 'Chico-Paradise', 'lowerName': 'chico-paradise'}, {'currency': 'usd', 'gasoline': '4.838', 'midGrade': '5.040', 'premium': '5.216', 'diesel': '5.393', 'name': 'Fresno', 'lowerName': 'fresno'}, {'currency': 'usd', 'gasoline': '4.975', 'midGrade': '5.187', 'premium': '5.330', 'diesel': '5.481', 'name': 'Los Angeles-Long Beach', 'lowerName': 'los angeles-long beach'}, {'currency': 'usd', 'gasoline': '4.894', 'midGrade': '5.099', 'premium': '5.279', 'diesel': '5.311', 'name': 'Merced', 'lowerName': 'merced'}, {'currency': 'usd', 'gasoline': '4.771', 'midGrade': '5.011', 'premium': '5.180', 'diesel': '5.300', 'name': 'Modesto', 'lowerName': 'modesto'}, {'currency': 'usd', 'gasoline': '4.993', 'midGrade': '5.206', 'premium': '5.387', 'diesel': '5.429', 'name': 'Oakland', 'lowerName': 'oakland'}, {'currency': 'usd', 'gasoline': '4.933', 'midGrade': '5.135', 'premium': '5.267', 'diesel': '5.278', 'name': 'Orange County', 'lowerName': 'orange county'}, {'currency': 'usd', 'gasoline': '4.765', 'midGrade': '4.918', 'premium': '5.064', 'diesel': '5.094', 'name': 'Redding', 'lowerName': 'redding'}, {'currency': 'usd', 'gasoline': '4.853', 'midGrade': '5.070', 'premium': '5.220', 'diesel': '5.282', 'name': 'Riverside', 'lowerName': 'riverside'}, {'currency': 'usd', 'gasoline': '4.940', 'midGrade': '5.141', 'premium': '5.324', 'diesel': '5.258', 'name': 'Sacramento', 'lowerName': 'sacramento'}, {'currency': 'usd', 'gasoline': '5.061', 'midGrade': '5.261', 'premium': '5.450', 'diesel': '5.621', 'name': 'Salinas', 'lowerName': 'salinas'}, {'currency': 'usd', 'gasoline': '4.972', 'midGrade': '5.180', 'premium': '5.335', 'diesel': '5.328', 'name': 'San Diego', 'lowerName': 'san diego'}, {'currency': 'usd', 'gasoline': '5.111', 'midGrade': '5.307', 'premium': '5.500', 'diesel': '5.529', 'name': 'San Francisco', 'lowerName': 'san francisco'}, {'currency': 'usd', 'gasoline': '4.952', 'midGrade': '5.154', 'premium': '5.327', 'diesel': '5.383', 'name': 'San Jose', 'lowerName': 'san jose'}, {'currency': 'usd', 'gasoline': '5.080', 'midGrade': '5.284', 'premium': '5.449', 'diesel': '5.808', 'name': 'San Luis Obispo-Atascadero-Paso Robles', 'lowerName': 'san luis obispo-atascadero-paso robles'}, {'currency': 'usd', 'gasoline': '4.971', 'midGrade': '5.162', 'premium': '5.304', 'diesel': '5.517', 'name': 'Santa Barbara-Santa Maria-Lompoc', 'lowerName': 'santa barbara-santa maria-lompoc'}, {'currency': 'usd', 'gasoline': '4.969', 'midGrade': '5.187', 'premium': '5.345', 'diesel': '5.556', 'name': 'Santa Cruz-Watsonville', 'lowerName': 'santa cruz-watsonville'}, {'currency': 'usd', 'gasoline': '5.098', 'midGrade': '5.301', 'premium': '5.472', 'diesel': '5.458', 'name': 'Santa Rosa', 'lowerName': 'santa rosa'}, {'currency': 'usd', 'gasoline': '4.828', 'midGrade': '5.046', 'premium': '5.226', 'diesel': '5.344', 'name': 'Stockton-Lodi', 'lowerName': 'stockton-lodi'}, {'currency': 'usd', 'gasoline': '4.907', 'midGrade': '5.112', 'premium': '5.280', 'diesel': '5.298', 'name': 'Vallejo-Fairfield', 'lowerName': 'vallejo-fairfield'}, {'currency': 'usd', 'gasoline': '5.015', 'midGrade': '5.218', 'premium': '5.362', 'diesel': '5.557', 'name': 'Ventura', 'lowerName': 'ventura'}, {'currency': 'usd', 'gasoline': '4.844', 'midGrade': '5.026', 'premium': '5.240', 'diesel': '5.458', 'name': 'Visalia-Tulare-Porterville', 'lowerName': 'visalia-tulare-porterville'}, {'currency': 'usd', 'gasoline': '4.900', 'midGrade': '5.132', 'premium': '5.343', 'diesel': '5.154', 'name': 'Yolo', 'lowerName': 'yolo'}, {'currency': 'usd', 'gasoline': '4.744', 'midGrade': '4.936', 'premium': '5.135', 'diesel': '5.158', 'name': 'Yuba City', 'lowerName': 'yuba city'}, {'currency': 'usd', 'gasoline': '4.772', 'midGrade': '4.962', 'premium': '5.187', 'diesel': '5.526', 'name': 'El Centro', 'lowerName': 'el centro'}, {'currency': 'usd', 'gasoline': '4.745', 'midGrade': '4.931', 'premium': '5.123', 'diesel': '5.316', 'name': 'Hanford-Corcoran', 'lowerName': 'hanford-corcoran'}, {'currency': 'usd', 'gasoline': '4.811', 'midGrade': '4.986', 'premium': '5.268', 'diesel': '5.532', 'name': 'Madera-Chowchilla', 'lowerName': 'madera-chowchilla'}, {'currency': 'usd', 'gasoline': '5.081', 'midGrade': '5.273', 'premium': '5.453', 'diesel': '5.391', 'name': 'Napa', 'lowerName': 'napa'}, {'currency': 'usd', 'gasoline': '4.891', 'midGrade': '5.078', 'premium': '5.243', 'diesel': '5.320', 'name': 'San Bernardino', 'lowerName': 'san bernardino'}, {'currency': 'usd', 'gasoline': '5.077', 'midGrade': '5.249', 'premium': '5.464', 'diesel': '5.460', 'name': 'San Rafael', 'lowerName': 'san rafael'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01c485-8a99-473e-b0af-0441e413b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd7d0b-f6be-4f57-a952-3470d1d00476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"currency\", \"gasoline\", \"midGrade\", \"premium\", \"diesel\", \"name\", \"lowerName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449fff74-0791-43ee-8e24-e4162e466f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('gas_price_3.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e16be-9332-4c85-8357-a13d0b376be5",
   "metadata": {},
   "source": [
    "# Ending of Mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2bf1f-eabc-47a2-bad9-435cd35f9849",
   "metadata": {},
   "source": [
    "# Beginning of Jim (presentation_1_jlh.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ff957-be9d-43d9-b95f-cd6673ecd5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
